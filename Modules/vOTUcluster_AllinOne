#!/usr/bin/env bash

# Record start time
start_time=$(date +%s)

# Initialize variables
INPUT_DIR=""
RAW_SEQ_DIR=""
OUTPUT_DIR=""
DATABASE=""
SAMPLETYPE=""
REASSEMBLE=false
VERSION="0.1.1"  # Define version number
CONCENTRATION_TYPE=""
THREADS=$(nproc)  # Default number of threads is the maximum available cores

# Set log file path
LOG_FILE=""

# Use getopts to handle short options and manually handle long options
while [[ $# -gt 0 ]]; do
  case $1 in
    -i)
      INPUT_DIR=$2
      shift 2
      ;;
    -r)
      RAW_SEQ_DIR=$2
      shift 2
      ;;
    -o)
      OUTPUT_DIR=$2
      LOG_FILE="${OUTPUT_DIR}/pipeline.log"  # Set log file path
      shift 2
      ;;
    -d)
      DATABASE=$2
      shift 2
      ;;
    -t)
      SAMPLETYPE=$2
      shift 2
      ;;
    -n)
      THREADS=$2
      shift 2
      ;;
    -v)
      echo "Version: $VERSION"
      exit 0
      ;;
    --non-con)
      CONCENTRATION_TYPE="non-concentration"
      shift
      ;;
    --con)
      CONCENTRATION_TYPE="concentration"
      shift
      ;;
    -h)
      echo "Usage: $0 [options]"
      echo ""
      echo "Options:"
      echo "  -i <input_path_to_search>   Specify the input directory to search for FASTA files."
      echo "  -r <input_path_raw_seqs>    Specify the input directory to search for raw seqs files."
      echo "  -o <output_path>            Specify the output directory for the results."
      echo "  -d <database_path>          Specify the path to the database required for analysis."
      echo "  -t <sample_type>            Specify the sample type: DNA, RNA, or Mix."
      echo "  -n <threads>                Specify the number of threads to use (default: max available cores)."
      echo "  --non-con                   Specify non-concentration processing."
      echo "  --con                       Specify concentration processing."
      echo "  --reassemble                Enable reassembly of bins."
      echo "  -v                          Display the version of this script."
      echo "  -h                          Display this help and exit."
      exit 0
      ;;
    --reassemble)
      REASSEMBLE=true
      shift
      ;;
    *)
      echo "Unknown option: $1" >&2
      exit 1
      ;;
  esac
done

# Ensure output directory and log file are created
if [ -z "$OUTPUT_DIR" ]; then
  echo "Error: Output directory not specified"
  exit 1
fi

# Function to add timestamp to log entries
log_with_timestamp() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" >> "$LOG_FILE"
}

# Create output directory if it doesn't exist
mkdir -p "$OUTPUT_DIR"

# Create log file if it doesn't exist
touch "$LOG_FILE"

# Log the command with a timestamp
log_with_timestamp "Run ViOTUcluster as command: $0 $@"

# Log all environment variables with a timestamp
log_with_timestamp "Environment variables at start:"
env >> "$LOG_FILE"

# Redirect all output to the log file and terminal with a timestamp
exec > >(while IFS= read -r line; do log_with_timestamp "$line"; echo "$line"; done) 2>&1

# Function to run modules and check for errors, with timestamp in log
run_module() {
    local module_name=$1
    local log_file=$2
    local command=$3

    log_with_timestamp "Starting $module_name..."
    module_start_time=$(date +%s)
    eval "$command" > "$log_file" 2>&1
    if [ $? -ne 0 ]; then
        log_with_timestamp "Error: $module_name failed. Check log: $log_file"
        exit 1
    fi
    module_end_time=$(date +%s)
    module_runtime=$((module_end_time - module_start_time))
    log_with_timestamp "$module_name completed in ${module_runtime} seconds."
}

# Check if paired files exist and have the correct format
for FILE in "${RAW_SEQ_DIR}"/*_R1.*; do
  BASENAME=$(basename "$FILE" | sed 's/_R1\..*//')
  PREFIX="${RAW_SEQ_DIR}/${BASENAME}"

  if [ -f "${PREFIX}_R1.fq" ] && [ -f "${PREFIX}_R2.fq" ]; then
    log_with_timestamp "Found paired files: ${PREFIX}_R1.fq and ${PREFIX}_R2.fq"
  elif [ -f "${PREFIX}_R1.fastq" ] && [ -f "${PREFIX}_R2.fastq" ]; then
    log_with_timestamp "Found paired files: ${PREFIX}_R1.fastq and ${PREFIX}_R2.fastq"
  elif [ -f "${PREFIX}_R1.fq.gz" ] && [ -f "${PREFIX}_R2.fq.gz" ]; then
    log_with_timestamp "Found paired files: ${PREFIX}_R1.fq.gz and ${PREFIX}_R2.fq.gz"
  elif [ -f "${PREFIX}_R1.fastq.gz" ] && [ -f "${PREFIX}_R2.fastq.gz" ]; then
    log_with_timestamp "Found paired files: ${PREFIX}_R1.fastq.gz and ${PREFIX}_R2.fastq.gz"
  else
    log_with_timestamp "Error: Paired-end files for ${BASENAME} not found in the expected formats (.fq, .fastq, .fq.gz, .fastq.gz)"
    exit 1
  fi
done

# Perform different processing based on CONCENTRATION_TYPE
if [ "$CONCENTRATION_TYPE" == "non-concentration" ]; then
    log_with_timestamp "Running non-concentration specific steps..."
elif [ "$CONCENTRATION_TYPE" == "concentration" ]; then
    log_with_timestamp "Running concentration specific steps..."
else
    log_with_timestamp "Error: Invalid concentration type."
    exit 1
fi

# Set Group variable based on SAMPLETYPE
case $SAMPLETYPE in
  DNA)
    Group="dsDNAphage, NCLDV, ssDNA, lavidaviridae"
    ;;
  RNA)
    Group="RNA, lavidaviridae"
    ;;
  Mix)
    Group="dsDNAphage, NCLDV, RNA, ssDNA, lavidaviridae"
    ;;
  *)
    log_with_timestamp "Unknown sample type: $SAMPLETYPE"
    exit 1
    ;;
esac

# Output selected processing type
log_with_timestamp "Processing with $CONCENTRATION_TYPE mode and $THREADS threads."

# Get bin folder location of current Conda environment
if [ -z "$CONDA_PREFIX" ]; then
  log_with_timestamp "Conda environment is not activated."
  exit 1
fi
ScriptDir="${CONDA_PREFIX}/bin"

# Export parameters as environment variables
export RAW_SEQ_DIR OUTPUT_DIR DATABASE SAMPLETYPE REASSEMBLE ASSEMBLY_SOFTWARE

mkdir -p "${OUTPUT_DIR}/Log"

# Run each module and check for errors
run_module "Raw sequences Process" "${OUTPUT_DIR}/Log/Preprocess.log" "Preprocess_module.sh '${RAW_SEQ_DIR}' '${ASSEMBLY_SOFTWARE}' '${OUTPUT_DIR}'"

# Update exported parameters
CONTIGS_DIR="${OUTPUT_DIR}/Contigs"
RAW_SEQ_DIR="${OUTPUT_DIR}/Cleanreads"
INPUT_DIR=${CONTIGS_DIR}

# Export parameters
export INPUT_DIR OUTPUT_DIR DATABASE SAMPLETYPE REASSEMBLE ScriptDir RAW_SEQ_DIR

# Run filter module
mkdir -p "${OUTPUT_DIR}/FilteredSeqs"
run_module "Filter contigs" "${OUTPUT_DIR}/Log/filter_contigs.log" "python '${ScriptDir}/filter_contigs.py' '${THREADS}' '${INPUT_DIR}' '${OUTPUT_DIR}/FilteredSeqs'"

# Find all .fa and .fasta files in the specified directory
FILES=$(find "${OUTPUT_DIR}/FilteredSeqs" -type f \( -name "*.fa" -o -name "*.fasta" \))
RawFILES=$(find "${INPUT_DIR}" -maxdepth 1 -type f \( -name "*.fa" -o -name "*.fasta" \))
#num_files=$(echo "$FILES" | wc -l)

# 根据 THREADS 输入确定每个文件的线程数
if [ "$THREADS" -eq 0 ]; then
  THREADS_PER_FILE=$(nproc)
else
  THREADS_PER_FILE=$THREADS
fi

#Test
THREADS_PER_FILE=$THREADS

# Export necessary variables and functions
export OUTPUT_DIR DATABASE Group FILES RawFILES CONCENTRATION_TYPE ScriptDir RAW_SEQ_DIR THREADS_PER_FILE THREADS

# Run viral prediction module
run_module "Viral prediction" "${OUTPUT_DIR}/Log/viral_prediction.log" "viral_prediction_module.sh"

# Cross Validation module
LOG_FILE="${OUTPUT_DIR}/Log/cross_validation.log"
KEYWORD="Cross Validation completed"
if [ -f "$LOG_FILE" ] && grep -q "$KEYWORD" "$LOG_FILE"; then
    log_with_timestamp "Cross Validation module already completed, skipping..."
else
    run_module "Cross Validation" "$LOG_FILE" "cross_validation_module.sh --${CONCENTRATION_TYPE}"
fi

# Run Binning and Merge module
run_module "Binning and merge" "${OUTPUT_DIR}/Log/binning_merge.log" "binning_merge_module.sh"

# Run Summary module
run_module "Summary" "${OUTPUT_DIR}/Log/summary.log" "summary_module.sh"

# Run dRep module
LOG_FILE="${OUTPUT_DIR}/Log/drep.log"
if [ -f "$LOG_FILE" ] && grep -q "Combined fasta files and quality summaries completed." "$LOG_FILE"; then
    log_with_timestamp "dRep module already completed, skipping..."
else
    run_module "dRep" "$LOG_FILE" "drep_module.sh"
fi

# Run TPM calculation module
LOG_FILE="${OUTPUT_DIR}/Log/TPM_caculate.log"
if [ -f "$LOG_FILE" ] && grep -q "TPM calculation completed successfully." "$LOG_FILE"; then
    log_with_timestamp "TPM calculation already completed, skipping..."
else
    run_module "TPM calculation" "$LOG_FILE" "TPM_caculate_Module.sh"
fi

# Run DRAM module
run_module "DRAM" "${OUTPUT_DIR}/Log/DRAM.log" "run_dram_analysis.sh '${OUTPUT_DIR}/Summary/Viralcontigs/vOTU.fasta' '${OUTPUT_DIR}/Summary/DRAM'"

# Run iPhop module
run_module "iPhop" "${OUTPUT_DIR}/Log/iPhop.log" "run_iphop_analysis.sh '${OUTPUT_DIR}/Summary/Viralcontigs/vOTU.fasta' '${OUTPUT_DIR}/Summary/iPhop'"

# Record end time and calculate total runtime of the entire pipeline
end_time=$(date +%s)
total_runtime=$((end_time - start_time))
log_with_timestamp "Total runtime: ${total_runtime} seconds"
